#################################################################
#								#
#	Créateur : Arthur YANG - Responsable Documentation 	#
#				 & Administratif		#
			
#	Date de création : 18/02/2025				#
#								#
#	Dernier modificateur : Arthur YANG			#
#	Date de modification : 18/02/2025			#
#								#
#		Version actuelle : 1.0				#
#								#
#################################################################


----------------------- Configuration et sécurisation du serveur de base de données prod ----------------------- 

Sources : https://www.val-r.fr/geek/os/linux/installer-un-serveur-linux-sous-debian/installation-et-configuration-du-serveur-mysql-mariadb/
		


Actions effectuées dans la VM : 

   => Connexion via root / mot de passe
   => apt update
   => apt upgrade

	
Installation de l'agent promtail (en root) :

	Installation de Promtail
  		 => Téléchargement et installation :
		On se place dans le chemin : /usr/local/bin/
		On télécharge le fichier zip de Promtail : wget https://github.com/grafana/loki/releases/download/v3.4.2/promtail-linux-amd64.zip
		Nous pouvons ensuite l'unzip : unzip (nom du fichier)
		C'est un fichier executable que l'on a.

	=> Configuration de Promtail :

	Nous devons ici, avoir un fichier nommé "promtail-config.yaml" pour la configuration de Promtail.
	Nous pouvons télécharger un modèle pré-existant : wget https://github.com/grafana/loki/blob/main/clients/cmd/promtail/promtail-local-config.yaml ou le créer nous même.
	Cela télécharge un modèle que l'on peut renommer comme nous le voulions.


=> Config .yaml personnalisé que nous effectuons :

--------------------------------------------------------------------------------------------

server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /var/lib/promtail/positions.yaml

clients:
  - url: http://192.168.7.133:3100/loki/api/v1/push  # Utilisation de l'IP du serveur Loki

scrape_configs:
  - job_name: SRV-BDD-PROD-AARD-SYSLOG
    static_configs:
      - targets:
          - localhost
        labels:
          job: SYSLOG-AARD-BDD-PROD
          host: SRV-BDD-PROD-AARD
          stream: stdout
          __path__: /var/log/syslog

  - job_name: SRV-BDD-PROD-AARD-CRON
    static_configs:
      - targets:
          - localhost
        labels:
          job: CRON-AARD-BDD-PROD
          host: SRV-BDD-PROD-AARD
          stream: stdout
          __path__: /var/log/cron.log

  - job_name: SRV-BDD-PROD-AARD-AUTHLOG
    static_configs:
      - targets:
          - localhost
        labels:
          job: AUTHLOG-AARD-BDD-PROD
          host: SRV-BDD-PROD-AARD
          stream: stdout
          __path__: /var/log/auth.log

  - job_name: SRV-BDD-PROD-AARD-KERNLOG
    static_configs:
      - targets:
          - localhost
        labels:
          job: KERNLOG-AARD-BDD-PROD
          host: SRV-BDD-PROD-AARD
          stream: stdout
          __path__: /var/log/kern.log

  - job_name: SRV-BDD-PROD-AARD-MYSQL
    static_configs:
      - targets:
          - localhost
        labels:
          job: MYSQL-AARD-BDD-PROD
          host: SRV-BDD-PROD-AARD
          stream: stdout
          __path__: /var/log/mysql/*.log

--------------------------------------------------------------------------------------------

On modifie les droits pour "MySQL" : 
	=> chmod -R 770 /var/log/mysql
	=> chgrp -R adm /var/log/mysql


=> Créer un dossier /var/lib/promtail/ : mkdir -p /var/lib/promtail
		=> chown -R prod:prod /var/lib/promtail
		=> chmod -R 750 /var/lib/promtail

	=> Nous mettons l'utilisateur créée plus tôt "prod" en tant que propriétaire et propriétaire groupe des fichiers de config de Loki.
	
		=> chown -R prod:prod promtail-config.yaml promtail-linux-amd64
		=> chmod 755 promtail-linux-amd64
		=> chmod 640 promtail-config.yaml


	=> Création du fichier : /etc/systemd/system/promtail.service

--------------------------------------------------------------------------------------------

[Unit]
Description=Promtail Loki
Wants=network-online.target
After=network-online.target

[Service]
Type=simple
User=prod
Group=prod
ExecStart=/usr/local/bin/promtail-linux-amd64 -config.file=/usr/local/bin/promtail-config.yaml

SyslogIdentifier=prod
Restart=always

[Install]
WantedBy=multi-user.target

--------------------------------------------------------------------------------------------


Commandes système et visualisation des logs en direct :

		=> systemctl enable promtail.service 
		=> systemctl start promtail.service
		=> systemctl status promtail.service
		=> journalctl -f -u promtail.service

	Normalement le service promtail est lancé.


Dans nos conteneurs LXC Debian, les logs semblent être dans le "journald" et non le syslog.

On installe "rsyslog" pour qu'ils puissent etre visible dans "syslog"

	=> apt install rsyslog -y
	=> systemctl enable rsyslog --now
	=> tail -f /var/log/syslog

Pour que notre utilisateur "prod" puissent avoir les droits de lecture de logs, on va lui ajouter dans le groupe adm : 

	=> usermod -aG adm prod
	=> systemctl restart promtail.service

En effet, Un problèmes d’accès aux fichiers /var/log/auth.log, /var/log/cron.log et /var/log/user.log par Grafana sera présent par le fait que l'on a paramétré le service promtail avec l'utilisateur "prod".

Faire de même avec le fichier "syslog" : 

	=> chown prod:root /var/log/syslog
	=> chmod 640 /var/log/syslog
	=> systemctl restart promtail.service

On peut rajouter : 

	=> chown prod:utmp /var/log/btmp


De manière générale, regarder les permissions des fichiers selon l'utilisateur qui utilise le service.


Lorsque on se connecte sur mariaDB, on peut voir que on peut toujours se connecter avec le root sans entrer de MDP.
Ce qui n'est pas du tout bon pour la sécurisation et configuration du serveur de BDD.

Pour ce faire, se connecter a mariadb : 

	=> Vérifier que mariadb utilise le plugin "mysql_native_password" comme plugin et pas "unix_socket" pour l'authentification.
	=> La commande pour vérifier est : SELECT user, host, plugin FROM mysql.user WHERE user='root';
	=> Après le bon plugin, entrer la commande suivante : ALTER USER 'root'@'localhost' IDENTIFIED VIA mysql_native_password USING PASSWORD('LEMDPCHOISIETDISPOSURBITWARDEN');
	=> FLUSH PRIVILEGES; (Pas obligatoire)

Tester la connexion après modification

	=> Exit
	=> mariadb -u root -p sans entrer de MDP. => Access denied ....
	=> Maintenant il faudra obligatoirment le mdp du root pour accéder à MariaDB.
	=> Biensur dans notre cas on pourra aussi accéder a mariaDB avec l'utilisateur créer pour la BDD de wordpress plus tot, avec son MDP aussi.

Pour les autres configurations basiques : Configuration des utilisateurs pour qu’ils puissent se connecter depuis l’extérieur, Configuration du serveur pour accepter les connexions extérieures et connexion au serveur web vers bdd etc...
Nous l'avons déja effectué dans le déploiement du serveur de BDD. Donc nous n'avons pas besoin de l'effectuer ici.


Nous laissons dans le fichier de conf "50-server.cnf" l'utilisateur "mariadb" executer le service de MariaDB pour la BDD car c'est un utilisateur système dédié à l'exécution du service, ce qui limite les risques de sécurité. Donc le user avec le commentaire peut etre laissé.

Toujours dans le meme fichier de conf : 

	=> ajouter les lignes : 
		=> max_connections = 100 # Limite le nombre de connexions simultanées
		=> local-infile=0 # Désactive l'importation de fichiers (évite certaines injections)
		=> skip-symbolic-links # Évite les liens symboliques dangereux
		=> query_cache_size=64M # Active le cache des requêtes SQL.
		=> query_cache_limit=2M

	=> Décommenter les lignes :

		=> general_log_file = /var/log/mysql/mysql.log
		=> general_log = 1
		=> log_error = /var/log/mysql/error.log
		=> log_slow_query_file = /var/log/mysql/mariadb-slow.log
		=> log_slow_query_file = 10
		=> log_slow_verbosity = query_plan,explain
		=> log-queries-not-using-indexes
		=> log_slow_min_examined_row_limit = 1000
		=> server-id = 1 et mettre "2 pour AARD" et "laisser 1 pour DRYN"
		=> log_bin = /var/log/mysql/mysql-bin.log
		=> expire_logs_days = 10
		=> max_binlog_size = 100M
		=> innodb_buffer_pool_size = 128M	Détermine combien de mémoire MariaDB utilise pour stocker les données les plus fréquemment utilisées.
		=> innodb_log_file_size = 64M	        Définit la taille des logs de transactions pour améliorer les performances.

	=> Créer le répertoire pour les logs de MariaDB et attribuer les droits
	
		=> Dans /var/log : 
			=> mkdir /var/log/mysql
			=> chmod -R 750 /var/log/mysql
			=> chown -R mysql:adm /var/log/mysql
			=> usermod -aG mysql prod

	=> on peut restart mariadb
	=> Cela nous sert a voir les logs liés a mariadb sur grafana


Des paramètres pourraient être ajoutés pour la configuration voir sécu du serveur, mais étant dans une conf maquette, nous n'avons énormement de RAM alloués au serveur et d'espace de stockage. Donc voici des lignes que l'on aurait pu ajouté mais que nous n'avons pas tous mis :

	=> innodb_flush_method	Définit comment MariaDB écrit sur le disque.
	=> innodb_flush_log_at_trx_commit	Définit quand les transactions sont écrites sur le disque.

Mais une dernière chose reste a configurer pour la lecture des logs depuis GRAFANA.
Il faut ajouter un job qui va chercher les fichier .log de mysql explicitement.

Donc il faut modifier et ajouter dans le fichier promtail-config.yaml : 

--------------------------------------------------------------------------------------------

server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /var/lib/promtail/positions.yaml

clients:
  - url: http://192.168.7.133:3100/loki/api/v1/push  # Utilisation de l'IP du serveur Loki

scrape_configs:
  - job_name: system
    static_configs:
      - targets:
          - localhost
        labels:
          job: varlogs
          host: SRV-BDD-PROD-AARD
          stream: stdout
          __path__: /var/log/*

  - job_name: mariadb_logs
    static_configs:
      - targets:
          - localhost
        labels:
          job: mariadb_prod
          host: SRV-BDD-PROD-AARD
          stream: stdout
          service: mysql
          __path__: /var/log/mysql/*

--------------------------------------------------------------------------------------------

On restart les services de la suite GRAFANA (Loki, promtail, grafana).

Maintenant sur GRAFANA, on pourra voir le nom du job qui ira chercher les fichiers logs de mysql.


On va installer pour la fin, NODE EXPORTER pour récupérer des informations plus précises que avec SNMP, qui surveillera les serveurs directs et non les équipements réseaux.

	=> Dans /usr/local/bin/ , on télécharge NODE Exporter qui va nous servir à récupérer les métriques du serveur BDD PROD ici.

		=> wget https://github.com/prometheus/node_exporter/releases/download/v1.9.0/node_exporter-1.9.0.linux-amd64.tar.gz
		=> tar -xvzf node_exporter-1.9.0.linux-amd64.tar.gz
		=> rm node_exporter-1.9.0.linux-amd64.tar.gz
		=> mv /usr/local/bin/node_exporter-1.9.0.linux-amd64/node_exporter /usr/local/bin/
		=> chown -R prod:prod /usr/local/bin/node_exporter
		=> chmod 755 /usr/local/bin/node_exporter
		=> rm -r /usr/local/bin/node_exporter-1.9.0.linux-amd64/


=> Création du fichier : nano /etc/systemd/system/node_exporter.service

--------------------------------------------------------------------------------------------

[Unit]
Description=Prometheus NODE Exporter
Wants=network-online.target
After=network-online.target

[Service]
Type=simple
User=prod
Group=prod
ExecStart=/usr/local/bin/node_exporter --web.listen-address=0.0.0.0:XXXX --collector.systemd --collector.processes

SyslogIdentifier=prod
Restart=always

[Install]
WantedBy=multi-user.target

--------------------------------------------------------------------------------------------

On a changé ici le port d'écoute de SNMP EXPORTER de Prometheus ici, dans le fichier du service. Ca ne se fait pas dans le .yml car il n'y pas de fichier .yml pour NODE Exporter .

Commandes système et visualisation des logs en direct :

		=> systemctl daemon-reexec
		=> systemctl daemon-reload
		=> systemctl enable node_exporter.service 
		=> systemctl start node_exporter.service 
		=> systemctl status node_exporter.service 
		=> journalctl -f -u node_exporter.service

Voila pour l'installation de NODE EXPORTER.


La partie SSL et autres (dossier emplacement des BDD ou FW hote ?) sera fait dans la partie plus "Sécurisation" en dessous.



=> Ajout du MOTD personnalisé sur la VM (et toutes) du NAS.
/etc/motd

Wizards & Dice | Shell Access for Debian GNU/Linux

***********************************************************************************************************************
*							LEGAL NOTICE
* This system is for authorized use only. All activities on this system may be * monitored and recorded. Unauthorized access or use is strictly prohibited * and may result in disciplinary action, criminal prosecution, or both. By * continuing to use and access this system, you consent to such monitoring.*

***********************************************************************************************************************


=> Ajout des éléments pour le monitoring des machines et de leurs MAJS.

	=> wget https://raw.githubusercontent.com/labmonkeys-space/apt-prometheus/main/script/apt-metrics.sh -O /usr/local/bin/apt-metrics.sh
	=> chmod 750 /usr/local/bin/apt-metrics.sh
	=> chown prod /usr/local/bin/apt-metrics.sh
	=> Puis on change tout le fichier : 

-------------------------------------------------------------------------------------------------------------------------

#!/bin/bash

OUT_FILE="/var/lib/node_exporter/textfile_collector/apt_updates.prom"

# Total updates
TOTAL_UPDATES=$(apt list --upgradeable 2>/dev/null | grep -v "Listing" | wc -l)

# Security updates (si 'unattended-upgrades' est installé)
SEC_UPDATES=$(apt list --upgradeable 2>/dev/null | grep security | wc -l)

# Reboot required (flag fichier)
if [ -f /var/run/reboot-required ]; then
  REBOOT_NEEDED=1
else
  REBOOT_NEEDED=0
fi

# Export en format Prometheus
echo "# HELP debian_apt_updates Nombre total de mises à jour APT" > "$OUT_FILE"
echo "# TYPE debian_apt_updates gauge" >> "$OUT_FILE"
echo "debian_apt_updates $TOTAL_UPDATES" >> "$OUT_FILE"

echo "# HELP debian_security_updates Nombre de mises à jour de sécurité" >> "$OUT_FILE"
echo "# TYPE debian_security_updates gauge" >> "$OUT_FILE"
echo "debian_security_updates $SEC_UPDATES" >> "$OUT_FILE"

echo "# HELP debian_reboot_required Système nécessite un redémarrage" >> "$OUT_FILE"
echo "# TYPE debian_reboot_required gauge" >> "$OUT_FILE"
echo "debian_reboot_required $REBOOT_NEEDED" >> "$OUT_FILE"

-------------------------------------------------------------------------------------------------------------------------

Dans le node_exporter.service

-------------------------------------------------------------------------------------------------------------------------

[Unit]
Description=Prometheus NODE Exporter
Wants=network-online.target
After=network-online.target

[Service]
Type=simple
User=prod
Group=prod
ExecStart=/usr/local/bin/node_exporter --web.listen-address=0.0.0.0:XXXX --collector.systemd --collector.processes --collector.textfile --collector.textfile.directory=/var/lib/node_exporter/textfile_collector

SyslogIdentifier=prod
Restart=always

[Install]
WantedBy=multi-user.target

-------------------------------------------------------------------------------------------------------------------------

=> mkdir -p /var/lib/node_exporter/textfile_collector
=> chown -R prod:root /var/lib/node_exporter/textfile_collector
=> chmod -R 770 /var/lib/node_exporter/textfile_collector

		=> systemctl daemon-reexec
		=> systemctl daemon-reload
		=> systemctl restart node_exporter.service 

Il faut maintenant faire un cron, pour executer le script "apt-metrics.sh" régulièrement : 

-------------------------------------------------------------------------------------------------------------------------
=> crontab -e

30 7 * * * /usr/local/bin/apt-metrics.sh

-------------------------------------------------------------------------------------------------------------------------

Maintenant il suffit sur grafana avec le dashboard, de regarder ce que nous voulons voir.


Mise en place de UFW : 

	=> apt install ufw

Politique par défaut

	=> ufw default deny incoming
	=> ufw default deny outgoing

Maintenant les règles précises : 

=> ufw allow from 172.16.14.1 to any port 14714 proto tcp comment 'SSH depuis bastion'
=> ufw allow from 192.168.7.132 to any port 14714 proto tcp comment 'SSH depuis SRV-RDS-AARD'
=> ufw allow from 192.168.7.128/28 to any port 9080 proto tcp comment 'VUE WEB DES TARGETS PROMTAIL'
=> ufw allow from 192.168.7.134 to any port 59051 proto tcp comment 'Prometheus avec node_exporter'
=> ufw allow from 172.16.7.1 to any port 29590 proto tcp comment 'Web vers BDD'
=> ufw allow out to 192.168.7.133 port 3100 proto tcp comment "Accès à Loki pour logs"
=> ufw allow out 80/tcp comment 'Sortie HTTP vers dépôts Linux'
=> ufw allow out 443/tcp comment 'Sortie HTTPS vers dépôts Linux'
=> ufw allow out to 192.168.7.140 port 53 proto udp comment 'Sortie DNS vers SRV-UCS-AARD'
=> ufw allow out 123/udp comment 'NTP'
=> ufw enable

Pour ajouter la possibilité de PING, il faut modifier le fichier /etc/ufw/before.rules et ajouter :

----------------------------------------------------------------------------------

# allow ICMP outbound (ping vers l'extérieur)
-A ufw-before-output -p icmp --icmp-type echo-request -j ACCEPT
-A ufw-before-output -p icmp --icmp-type destination-unreachable -j ACCEPT
-A ufw-before-output -p icmp --icmp-type time-exceeded -j ACCEPT
-A ufw-before-output -p icmp --icmp-type echo-reply -j ACCEPT

----------------------------------------------------------------------------------

Voila pour UFW, il faudra voir si d'autres problèmes sont présent, comme ça on ajoute ou enleve des règles.


Installation Apparmor : 

=> apt install apparmor apparmor-utils

Vérifier que AppArmor est actif

=> aa-status

Activer AppArmor au démarrage

=> systemctl enable apparmor

Dans => nano /etc/apparmor.d/usr.sbin.mariadbd

----------------------------------------------

/usr/sbin/mariadbd {
  # Autorisations de lecture sur /var/log/
  /var/log/ r,
  /var/log/** rwk,
}

----------------------------------------------

On recharge le profil

=> apparmor_parser -r /etc/apparmor.d/usr.sbin.mariadbd

Puis on met en mode complain : 

=> aa-complain /etc/apparmor.d/usr.sbin.mariadbd

Je ne ferai pas plus de choses, en soit apparmor est installé mais il faudrait précisément pour certains services, donc faire des profiles minutieux.
Sauf que => Pas le temps.


Installation lynis + fail2ban

=> Executer lynis dans syslog : lynis audit system | logger -t lynis

OU

=> Executer le script dans /usr/local/bin/lynis-syslog.sh

nano /usr/local/bin/lynis-syslog.sh

Script : 

--------------------------------------

#!/bin/bash
lynis audit system | logger -t lynis

--------------------------------------

=> chmod 750 /usr/local/bin/lynis-syslog.sh
=> chown prod /usr/local/bin/lynis-syslog.sh

Pas de cron.

On peut voir depuis GRAFANA dans les logs, le résultat.

Fail2Ban : 

=> apt install fail2ban -y
=> systemctl enable fail2ban
=> systemctl start fail2ban

On ne modifie jamais directement jail.conf. On crée un fichier jail.local :

=> cp /etc/fail2ban/jail.conf /etc/fail2ban/jail.local
=> nano /etc/fail2ban/jail.local

--------------------------

[sshd]
enabled = true
port    = ssh
logpath = %(sshd_log)s
backend = %(sshd_backend)s
maxretry = 5
bantime = 500
findtime = 600

--------------------------

=> systemctl restart fail2ban
=> fail2ban-client status
=> fail2ban-client status sshd


Installation Clamav : 

=> apt install clamav -y
=> systemctl stop clamav-freshclam
=> freshclam
=> clamscan -r /home | logger -t clamav (pas obligatoire)